@page
@model AvatarModel
@{
    ViewData["Title"] = "Medical Instructor Avatar";
}

<link rel="stylesheet" href="~/css/custom.css" />
<style>
    @@keyframes pulse {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.5; }
    }
    .fa-circle[style*="animation"] {
        display: inline-block;
    }
</style>

<div class="container-fluid h-100 py-4">
    <div class="row h-100 g-4">
        <!-- Main Avatar Area -->
        <div class="col-lg-12 d-flex flex-column">
            <div class="chat-container flex-grow-1 d-flex flex-column">
                <!-- Header -->
                <div class="chat-header">
                    <h4 class="mb-2">
                        <i class="fas fa-user-md me-2"></i>
                        Medical Instructor Avatar
                        <span class="badge bg-light text-dark ms-2" id="statusBadge">
                            <i class="fas fa-circle text-secondary"></i> Ready
                        </span>
                    </h4>
                    <small class="text-white-50">
                        <i class="fas fa-id-card me-1"></i>
                        Session: <span id="sessionIdDisplay">-</span>
                    </small>
                </div>
                
                <!-- Video Container -->
                <div class="avatar-video-container position-relative" style="background: #000; min-height: 500px; display: flex; align-items: center; justify-content: center;">
                    <video id="avatarVideo" autoplay playsinline muted style="width: 100%; max-width: 800px; border: 1px solid #ccc; background:#000;" hidden></video>
                    <audio id="avatarAudio" autoplay volume="1.0"></audio>
                    <div id="placeholder" class="text-center text-white p-5">
                        <i class="fas fa-user-md fa-5x mb-4" style="opacity: 0.5;"></i>
                        <h5>Medical Instructor Avatar</h5>
                        <p class="text-white-50">Click "Start Session" to begin your conversation</p>
                    </div>
                    <div id="loading" class="text-center text-white p-5" hidden>
                        <div class="spinner-border text-light mb-3" role="status"></div>
                        <p id="loadingText">Connecting...</p>
                    </div>
                </div>
                
                <!-- Chat History -->
                <div class="chat-messages" id="chatHistory" style="height: 200px; overflow-y: auto; background: #f8f9fa; padding: 1rem;">
                    <div class="text-center text-muted py-4">
                        <i class="fas fa-comments fa-2x mb-2"></i>
                        <p class="mb-0">Conversation transcript will appear here</p>
                    </div>
                </div>
                
                <!-- Input Controls -->
                <div class="chat-input-container">
                    <div class="input-group">
                        <input type="text" id="messageInput" class="form-control" placeholder="Ask your medical question..." maxlength="500" disabled>
                        <button class="btn btn-primary" type="button" id="sendButton" disabled>
                            <i class="fas fa-paper-plane me-2"></i>Send
                        </button>
                        <button class="btn btn-info" type="button" id="recordButton" disabled>
                            <i class="fas fa-microphone me-2"></i>Voice
                        </button>
                        <button class="btn btn-success" type="button" id="startButton">
                            <i class="fas fa-play me-2"></i>Start Session
                        </button>
                        <button class="btn btn-danger" type="button" id="stopButton" hidden>
                            <i class="fas fa-stop me-2"></i>Stop Session
                        </button>
                    </div>
                    <div class="mt-2 d-flex justify-content-between align-items-center">
                        <small class="text-muted">
                            <i class="fas fa-microphone me-1"></i>
                            Type your question or click Voice button to speak
                        </small>
                        <small class="text-muted">
                            <i class="fas fa-video me-1"></i>
                            Powered by HeyGen Avatar + RAG-enhanced medical knowledge
                        </small>
                    </div>
                    <div id="recordingStatus" class="mt-2" hidden>
                        <small class="text-warning">
                            <i class="fas fa-circle me-1" style="animation: pulse 1s infinite;"></i>
                            Recording... Click again to stop and send
                        </small>
                    </div>
                </div>
            </div>
        </div>

        <!-- Sources Panel (hidden; no longer needed in UI) -->
        <div class="col-lg-4" style="display:none;">
            <div class="logs-panel sources-panel h-100 d-flex flex-column">
                <div class="sources-header">
                    <h5 class="mb-0">
                        <i class="fas fa-link me-2"></i>
                        Reference Sources
                    </h5>
                    <p class="text-white-50 small mb-0">Medical documents referenced in the avatar's response.</p>
                </div>
                <div class="sources-body" id="sourcesContainer">
                    <div class="text-center text-muted py-5">
                        <i class="fas fa-graduation-cap fa-3x mb-3" style="color: #94a3b8;"></i>
                        <p>No sources yet</p>
                        <p class="small">Start a conversation to see cited references.</p>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

@section Scripts {
<!-- LiveKit Client Library -->
<script src="https://cdn.jsdelivr.net/npm/livekit-client/dist/livekit-client.umd.min.js"></script>
<script>
(function() {
    'use strict';

    // ============================================
    // Configuration & State
    // ============================================
    const API_BASE = '/api/avatar/v2/streaming';
    let liveKitRoom = null;
    let sessionData = null;
    let streamingToken = null; // Cache the token used to create the session
    let isSessionActive = false;
    
    // Helper function to check video element state (can be called from console)
    window.checkVideoState = function() {
        const v = document.getElementById('avatarVideo');
        if (!v) {
            console.log('[DEBUG] Video element not found');
            return null;
        }
        
        const computedStyle = window.getComputedStyle(v);
        const state = {
            element: v,
            currentTime: v.currentTime,
            paused: v.paused,
            readyState: v.readyState,
            videoWidth: v.videoWidth,
            videoHeight: v.videoHeight,
            muted: v.muted,
            hidden: v.hidden,
            srcObject: !!v.srcObject,
            srcObjectTracks: v.srcObject ? {
                video: v.srcObject.getVideoTracks().length,
                audio: v.srcObject.getAudioTracks().length
            } : null,
            computedStyle: {
                display: computedStyle.display,
                visibility: computedStyle.visibility,
                width: computedStyle.width,
                height: computedStyle.height,
                zIndex: computedStyle.zIndex,
                position: computedStyle.position,
                opacity: computedStyle.opacity
            }
        };
        
        console.log('[DEBUG] Video element state:', state);
        return state;
    };
    
    // Helper function to force video visibility (for debugging)
    window.forceVideoVisible = function() {
        const v = document.getElementById('avatarVideo');
        if (!v) {
            console.error('[DEBUG] Video element not found');
            return;
        }
        
        // Force visibility with inline styles
        v.style.position = 'relative';
        v.style.width = '640px';
        v.style.height = '360px';
        v.style.zIndex = '9999';
        v.style.background = 'black';
        v.style.display = 'block';
        v.style.visibility = 'visible';
        v.hidden = false;
        
        // Hide placeholder
        const placeholder = document.getElementById('placeholder');
        if (placeholder) {
            placeholder.hidden = true;
        }
        
        // Try to play
        v.play().catch(err => console.error('[DEBUG] Force play failed:', err));
        
        console.log('[DEBUG] Video forced visible - check if avatar is moving now');
        console.log('[DEBUG] Video state:', window.checkVideoState());
    };
    
    // Audio recording state
    let mediaRecorder = null;
    let audioChunks = [];
    let isRecording = false;
    let audioStream = null;

    // ============================================
    // Browser Speech Recognition (Web Speech API)
    // ============================================
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    let recognition = null;

    if (SpeechRecognition) {
        try {
            recognition = new SpeechRecognition();
            recognition.lang = 'en-US';
            recognition.interimResults = false;
            recognition.maxAlternatives = 1;

            recognition.addEventListener('result', (event) => {
                const transcript = event.results[0][0].transcript;
                console.log('[STT] Heard:', transcript);

                // Reuse existing text chat pipeline
                elements.messageInput.value = transcript;
                if (isSessionActive && transcript && transcript.trim()) {
                    sendMessage();
                }
            });

            recognition.addEventListener('end', () => {
                console.log('[STT] Recognition ended');
                elements.recordButton.disabled = false;
                elements.recordButton.innerHTML = '<i class="fas fa-microphone me-2"></i>Voice';
                elements.recordButton.classList.remove('btn-danger');
                elements.recordButton.classList.add('btn-info');
                elements.recordingStatus.hidden = true;
                if (isSessionActive) {
                    updateStatus('Connected', 'success');
                }
            });

            recognition.addEventListener('error', (event) => {
                console.error('[STT] Recognition error:', event.error);
                addMessage('System', `Speech recognition error: ${event.error}`, true);
            });

            console.log('[STT] Web Speech API initialized');
        } catch (err) {
            console.warn('[STT] Failed to initialize Web Speech API:', err);
            recognition = null;
        }
    } else {
        console.log('[STT] Web Speech API not supported in this browser');
    }

    // ============================================
    // DOM Elements
    // ============================================
    const elements = {
        video: document.getElementById('avatarVideo'),
        audio: document.getElementById('avatarAudio'),
        placeholder: document.getElementById('placeholder'),
        loading: document.getElementById('loading'),
        loadingText: document.getElementById('loadingText'),
        chatHistory: document.getElementById('chatHistory'),
        messageInput: document.getElementById('messageInput'),
        sendButton: document.getElementById('sendButton'),
        recordButton: document.getElementById('recordButton'),
        startButton: document.getElementById('startButton'),
        stopButton: document.getElementById('stopButton'),
        statusBadge: document.getElementById('statusBadge'),
        sessionIdDisplay: document.getElementById('sessionIdDisplay'),
        sourcesContainer: document.getElementById('sourcesContainer'),
        recordingStatus: document.getElementById('recordingStatus')
    };

    // ============================================
    // Utility Functions
    // ============================================
    function escapeHtml(text) {
        const div = document.createElement('div');
        div.textContent = text;
        return div.innerHTML;
    }

    function updateStatus(text, type = 'secondary') {
        const icons = {
            secondary: 'fa-circle',
            success: 'fa-circle',
            warning: 'fa-circle',
            danger: 'fa-circle'
        };
        elements.statusBadge.innerHTML = `<i class="fas ${icons[type]} text-${type}"></i> ${text}`;
    }

    function showLoading(text = 'Loading...') {
        elements.loadingText.textContent = text;
        elements.loading.hidden = false;
        elements.placeholder.hidden = true;
    }

    function hideLoading() {
        elements.loading.hidden = true;
    }

    function addMessage(sender, message, isError = false) {
        // Remove placeholder
        const placeholder = elements.chatHistory.querySelector('.text-center');
        if (placeholder) placeholder.remove();

        const messageDiv = document.createElement('div');
        messageDiv.className = `mb-2 p-2 rounded ${isError ? 'bg-danger text-white' : sender === 'User' ? 'bg-primary text-white ms-auto' : 'bg-light'}`;
        messageDiv.style.maxWidth = '85%';
        messageDiv.style.marginLeft = sender === 'User' ? 'auto' : '0';

        const icon = sender === 'User' ? 'fa-user' : isError ? 'fa-exclamation-circle' : 'fa-user-md';
        const escapedMessage = escapeHtml(message).replace(/\n/g, '<br>');
        
        messageDiv.innerHTML = `
            <div class="d-flex align-items-start">
                <span><i class="fas ${icon} me-2"></i></span>
                <div class="flex-grow-1">
                    <strong>${escapeHtml(sender)}:</strong>
                    <div>${escapedMessage}</div>
                    <small class="text-muted">${new Date().toLocaleTimeString()}</small>
                </div>
            </div>
        `;

        elements.chatHistory.appendChild(messageDiv);
        elements.chatHistory.scrollTop = elements.chatHistory.scrollHeight;
    }

    function updateSources(sources, isFallback) {
        elements.sourcesContainer.innerHTML = '';

        if (isFallback) {
            elements.sourcesContainer.innerHTML = `
                <div class="text-center text-muted py-5">
                    <i class="fas fa-plug-circle-exclamation fa-3x mb-3" style="color: #ea580c;"></i>
                    <p>Reference services are offline.</p>
                </div>
            `;
            return;
        }

        if (!sources || sources.length === 0) {
            elements.sourcesContainer.innerHTML = `
                <div class="text-center text-muted py-5">
                    <i class="fas fa-graduation-cap fa-3x mb-3" style="color: #94a3b8;"></i>
                    <p>No sources yet</p>
                </div>
            `;
            return;
        }

        sources.forEach(source => {
            if (!source || !source.url) return;

            const entry = document.createElement('div');
            entry.className = 'source-entry mb-3 p-3 bg-dark rounded';
            
            const titleLink = document.createElement('a');
            titleLink.className = 'text-white text-decoration-none';
            titleLink.href = source.url;
            titleLink.target = '_blank';
            titleLink.textContent = source.title || 'Reference material';
            titleLink.style.fontWeight = 'bold';

            entry.appendChild(titleLink);

            if (source.preview) {
                const preview = document.createElement('p');
                preview.className = 'text-white-50 small mt-2 mb-0';
                preview.textContent = source.preview;
                entry.appendChild(preview);
            }

            elements.sourcesContainer.appendChild(entry);
        });
    }

    // ============================================
    // LiveKit Connection
    // ============================================
    async function connectToLiveKit(url, accessToken) {
        return new Promise((resolve, reject) => {
            // Wait for LiveKit client to load
            let attempts = 0;
            const maxAttempts = 20;
            
            function checkLiveKit() {
                const LiveKit = window.LivekitClient;
                if (LiveKit) {
                    try {
                        const room = new LiveKit.Room({
                            adaptiveStream: true,
                            dynacast: true
                        });

                        // Set up event handlers
                        let videoTrackReceived = false;
                        let audioTrackReceived = false;

                        room.on(LiveKit.RoomEvent.TrackSubscribed, (track, publication, participant) => {
                            console.log('[LK] TrackSubscribed:', track.kind, {
                                participant: participant?.identity || 'unknown',
                                sid: track.sid,
                                trackId: track.trackId,
                                isMuted: track.isMuted,
                                isSubscribed: track.isSubscribed
                            });
                            
                            if (track.kind === LiveKit.Track.Kind.Video || track.kind === 'video') {
                                // Use track.attach() like MarvelCrud - this is the LiveKit recommended way
                                track.attach(elements.video);
                                elements.video.muted = true;
                                elements.video.playsInline = true;
                                elements.video.autoplay = true;
                                elements.video.hidden = false;
                                elements.placeholder.hidden = true;
                                videoTrackReceived = true;
                                
                                const playPromise = elements.video.play();
                                if (playPromise !== undefined) {
                                    playPromise
                                        .then(() => {
                                            console.log('[LK] Video play() succeeded');
                                        })
                                        .catch((err) => {
                                            console.error('[LK] Video play error:', err);
                                        });
                                }
                                
                                if (audioTrackReceived) {
                                    hideLoading();
                                    updateStatus('Connected', 'success');
                                } else {
                                    updateStatus('Connecting audio...', 'warning');
                                }
                                
                            } else if (track.kind === LiveKit.Track.Kind.Audio || track.kind === 'audio') {
                                // Use track.attach() like MarvelCrud - this is the LiveKit recommended way
                                console.log('[LK] Audio track subscribed, attaching to element');
                                track.attach(elements.audio);
                                elements.audio.autoplay = true;
                                elements.audio.muted = false;
                                elements.audio.volume = 1.0;
                                audioTrackReceived = true;
                                
                                // Try to play audio - browsers may require user interaction
                                const playPromise = elements.audio.play();
                                if (playPromise !== undefined) {
                                    playPromise
                                        .then(() => {
                                            console.log('[LK] Audio playback started successfully');
                                            if (videoTrackReceived) {
                                                hideLoading();
                                                updateStatus('Connected', 'success');
                                            }
                                        })
                                        .catch((error) => {
                                            console.warn('[LK] Audio play was prevented:', error);
                                        });
                                }
                                
                                if (videoTrackReceived) {
                                    hideLoading();
                                    updateStatus('Connected', 'success');
                                }
                            }
                        });

                        room.on(LiveKit.RoomEvent.TrackUnsubscribed, (track, publication, participant) => {
                            console.log(`Track unsubscribed: ${track.kind} from ${participant?.identity || 'unknown'}`);
                            // Detach track from elements
                            if (track.kind === 'video') {
                                track.detach(elements.video);
                            } else if (track.kind === 'audio') {
                                track.detach(elements.audio);
                            }
                            if (track.kind === 'video') {
                                videoTrackReceived = false;
                                elements.video.hidden = true;
                                elements.placeholder.hidden = false;
                                updateStatus('Video disconnected', 'warning');
                            } else if (track.kind === 'audio') {
                                audioTrackReceived = false;
                                if (videoTrackReceived) {
                                    updateStatus('Audio disconnected', 'warning');
                                }
                            }
                        });

                        room.on(LiveKit.RoomEvent.Disconnected, () => {
                            console.log('Room disconnected');
                            updateStatus('Disconnected', 'danger');
                            isSessionActive = false;
                            elements.messageInput.disabled = true;
                            elements.sendButton.disabled = true;
                        });

                        // Connect with timeout
                        const connectPromise = room.connect(url, accessToken);
                        const timeoutPromise = new Promise((_, rejectTimeout) => 
                            setTimeout(() => rejectTimeout(new Error('Connection timeout after 30 seconds')), 30000)
                        );

                        Promise.race([connectPromise, timeoutPromise])
                            .then(() => {
                                console.log('LiveKit connected successfully');
                                resolve(room);
                            })
                            .catch(reject);
                    } catch (error) {
                        reject(error);
                    }
                } else if (attempts < maxAttempts) {
                    attempts++;
                    setTimeout(checkLiveKit, 500);
                } else {
                    reject(new Error('LiveKit client library failed to load'));
                }
            }

            checkLiveKit();
        });
    }

    // ============================================
    // API Calls
    // ============================================
    async function createSession() {
        console.log('[API] Calling POST', `${API_BASE}/session/create`);
        const response = await fetch(`${API_BASE}/session/create`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' }
        });

        console.log('[API] session/create response status:', response.status, response.statusText);

        if (!response.ok) {
            const error = await response.json();
            console.error('[API] session/create error:', error);
            throw new Error(error.message || `HTTP ${response.status}`);
        }

        const data = await response.json();
        console.log('[API] session/create success:', { 
            sessionId: data.sessionId?.substring(0, 8) + '...', 
            hasStreamingToken: !!data.streamingToken,
            hasUrl: !!data.url,
            hasAccessToken: !!data.accessToken
        });
        return data;
    }

    async function sendTask(sessionId, message) {
        if (!streamingToken) {
            console.error('[API] CRITICAL: streamingToken is missing! Cannot send task.');
            throw new Error('Streaming token is required. Please restart the session.');
        }

        const payload = {
            message: message,
            conversationId: sessionId,
            streamingToken: streamingToken // Include the cached token
        };

        console.log('[API] Calling POST', `${API_BASE}/task`, {
            conversationId: sessionId,
            messageLength: message.length,
            hasStreamingToken: !!streamingToken,
            streamingTokenLength: streamingToken.length
        });

        const response = await fetch(`${API_BASE}/task`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify(payload)
        });

        console.log('[API] /task response status:', response.status, response.statusText);

        if (!response.ok) {
            let errorMessage = `HTTP ${response.status}`;
            try {
                const errorData = await response.json();
                console.error('[API] /task error response:', errorData);
                errorMessage = errorData.error || errorData.message || errorMessage;
            } catch (e) {
                // If response isn't JSON, try to get text
                try {
                    const errorText = await response.text();
                    console.error('[API] /task error text:', errorText);
                    errorMessage = errorText || errorMessage;
                } catch (e2) {
                    // Use default error message
                }
            }
            throw new Error(errorMessage);
        }

        const data = await response.json();
        console.log('[API] /task success:', { 
            hasTranscript: !!data.transcript,
            transcriptLength: data.transcript?.length || 0,
            sourceCount: data.sources?.length || 0
        });
        return data;
    }

    async function stopSession(sessionId) {
        try {
            await fetch(`${API_BASE}/session/stop`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ 
                    sessionId: sessionId,
                    streamingToken: streamingToken // Include the cached token
                })
            });
        } catch (error) {
            console.error('Error stopping session:', error);
        }
    }

    // ============================================
    // Session Management
    // ============================================
    async function startSession() {
        console.log('[SESSION] startSession() called');
        try {
            elements.startButton.disabled = true;
            showLoading('Creating session...');
            updateStatus('Creating session...', 'warning');

            // Step 1: Create streaming session
            console.log('[SESSION] Step 1: Creating session via API...');
            const sessionResponse = await createSession();
            console.log('[SESSION] Session created successfully:', {
                sessionId: sessionResponse.sessionId?.substring(0, 8) + '...',
                hasStreamingToken: !!sessionResponse.streamingToken
            });
            sessionData = sessionResponse;
            streamingToken = sessionResponse.streamingToken; // Cache the token for reuse
            elements.sessionIdDisplay.textContent = sessionResponse.sessionId.substring(0, 8) + '...';

            showLoading('Connecting to avatar...');
            updateStatus('Connecting...', 'warning');

            // Step 2: Connect to LiveKit
            liveKitRoom = await connectToLiveKit(sessionResponse.url, sessionResponse.accessToken);

            // Step 3: Send initial greeting to make avatar animate
            // Note: Avatar will remain static/idle until it receives a task
            try {
                console.log('Sending initial greeting to animate avatar...');
                // Send a greeting that establishes Dr. Dexter as the instructor
                // This will be processed through RAG+personality to create Dr. Dexter's introduction
                const greeting = "Briefly introduce yourself as Dr. Dexter, an experienced ER physician. Mention you have access to a medical knowledge database and ask what topic they'd like to learn about.";
                const greetingResponse = await sendTask(sessionResponse.sessionId, greeting);
                
                console.log('Greeting sent successfully, avatar should now be animating');
                
                if (greetingResponse.transcript) {
                    addMessage('Avatar', greetingResponse.transcript);
                }
                if (greetingResponse.sources) {
                    updateSources(greetingResponse.sources, greetingResponse.isFallback);
                }
            } catch (error) {
                console.error('Error sending greeting:', error);
                // Inform user but don't fail session
                addMessage('System', `Note: Initial greeting failed (${error.message}). The avatar may appear static until you send a message.`, false);
            }

            // Step 4: Enable UI (Voice only - text input disabled)
            isSessionActive = true;
            elements.messageInput.disabled = false;
            elements.sendButton.disabled = false;
            elements.recordButton.disabled = false;
            elements.startButton.hidden = true;
            elements.stopButton.hidden = false;
            updateStatus('Connected', 'success');

        } catch (error) {
            console.error('Error starting session:', error);
            addMessage('System', `Failed to start session: ${error.message}`, true);
            updateStatus('Error', 'danger');
            hideLoading();
            elements.placeholder.hidden = false;
            elements.startButton.disabled = false;

            // Cleanup
            if (sessionData) {
                await stopSession(sessionData.sessionId);
            }
            if (liveKitRoom) {
                try {
                    liveKitRoom.disconnect();
                } catch (e) {
                    console.error('Error disconnecting:', e);
                }
            }
            
            // Reset state
            sessionData = null;
            streamingToken = null;
        }
    }

    async function stopSessionHandler() {
        try {
            elements.stopButton.disabled = true;
            updateStatus('Stopping...', 'warning');

            if (sessionData) {
                await stopSession(sessionData.sessionId);
            }

            if (liveKitRoom) {
                liveKitRoom.disconnect();
            }

            // Reset UI
            isSessionActive = false;
            sessionData = null;
            liveKitRoom = null;

            elements.video.hidden = true;
            elements.placeholder.hidden = false;
            hideLoading();
            elements.messageInput.disabled = true;
            elements.sendButton.disabled = true;
            elements.recordButton.disabled = true;
            elements.startButton.hidden = false;
            elements.stopButton.hidden = true;
            elements.startButton.disabled = false;
            elements.sessionIdDisplay.textContent = '-';
            updateStatus('Ready', 'secondary');
            sessionData = null;
            streamingToken = null; // Clear cached token
            addMessage('System', 'Session stopped.', false);
            
            // Stop any active recording
            if (isRecording) {
                stopRecording();
            }
            if (audioStream) {
                audioStream.getTracks().forEach(track => track.stop());
                audioStream = null;
            }

        } catch (error) {
            console.error('Error stopping session:', error);
            addMessage('System', `Error stopping session: ${error.message}`, true);
            elements.stopButton.disabled = false;
        }
    }

    async function sendMessage() {
        console.log('[MESSAGE] sendMessage() called');
        const message = elements.messageInput.value.trim();
        if (!message || !isSessionActive) {
            console.warn('[MESSAGE] Cannot send - message empty or session not active', { message: !!message, isSessionActive });
            return;
        }

        if (!sessionData || !sessionData.sessionId) {
            console.error('[MESSAGE] CRITICAL: sessionData is missing!');
            addMessage('System', 'Session not initialized. Please start a session first.', true);
            return;
        }

        if (!streamingToken) {
            console.error('[MESSAGE] CRITICAL: streamingToken is missing!');
            addMessage('System', 'Streaming token missing. Please restart the session.', true);
            return;
        }

        console.log('[MESSAGE] Sending message via API:', {
            sessionId: sessionData.sessionId,
            messageLength: message.length,
            hasStreamingToken: !!streamingToken
        });

        addMessage('User', message);
        elements.messageInput.value = '';
        elements.sendButton.disabled = true;
        showLoading('Processing...');
        updateStatus('Processing...', 'warning');

        try {
            const response = await sendTask(sessionData.sessionId, message);
            
            if (response.transcript) {
                addMessage('Avatar', response.transcript);
            }
            if (response.sources) {
                updateSources(response.sources, response.isFallback);
            }

            hideLoading();
            updateStatus('Connected', 'success');
        } catch (error) {
            console.error('Error sending message:', error);
            addMessage('System', `Error: ${error.message}`, true);
            hideLoading();
            updateStatus('Error', 'danger');
        } finally {
            elements.sendButton.disabled = false;
        }
    }

    // ============================================
    // Audio Recording Functions
    // ============================================
    
    // Helper function to get supported MediaRecorder mimeType
    function getSupportedMimeType() {
        const types = [
            'audio/webm;codecs=opus',
            'audio/webm',
            'audio/ogg;codecs=opus',
            'audio/ogg',
            'audio/mp4',
            'audio/mpeg'
        ];
        
        for (const type of types) {
            if (MediaRecorder.isTypeSupported(type)) {
                console.log('[RECORD] Using mimeType:', type);
                return type;
            }
        }
        
        // Fallback: let browser choose
        console.warn('[RECORD] No preferred mimeType found, using browser default');
        return '';
    }

    async function startRecording() {
        try {
            // Check if MediaRecorder is supported
            if (!window.MediaRecorder) {
                throw new Error('MediaRecorder API is not supported in this browser. Please use Chrome, Edge, or Firefox.');
            }

            // Request microphone access
            console.log('[RECORD] Requesting microphone access...');
            audioStream = await navigator.mediaDevices.getUserMedia({ 
                audio: {
                    channelCount: 1,
                    sampleRate: 16000,
                    echoCancellation: true,
                    noiseSuppression: true
                } 
            });
            console.log('[RECORD] Microphone access granted');

            // Get supported mimeType
            const mimeType = getSupportedMimeType();
            const options = mimeType ? { mimeType: mimeType } : {};

            // Create MediaRecorder with supported format
            try {
                mediaRecorder = new MediaRecorder(audioStream, options);
                console.log('[RECORD] MediaRecorder created with options:', options);
            } catch (recorderError) {
                console.error('[RECORD] Failed to create MediaRecorder with options:', options, recorderError);
                // Try without options (browser default)
                mediaRecorder = new MediaRecorder(audioStream);
                console.log('[RECORD] MediaRecorder created with browser default');
            }

            // Store the actual mimeType used
            const actualMimeType = mediaRecorder.mimeType || 'audio/webm';
            console.log('[RECORD] Actual MediaRecorder mimeType:', actualMimeType);

            audioChunks = [];

            mediaRecorder.ondataavailable = (event) => {
                if (event.data && event.data.size > 0) {
                    console.log('[RECORD] Data chunk received:', event.data.size, 'bytes');
                    audioChunks.push(event.data);
                }
            };

            mediaRecorder.onerror = (event) => {
                console.error('[RECORD] MediaRecorder error:', event.error);
                addMessage('System', `Recording error: ${event.error?.message || 'Unknown error'}`, true);
                stopRecording();
            };

            mediaRecorder.onstop = async () => {
                console.log('[RECORD] Recording stopped, chunks:', audioChunks.length);
                
                if (audioChunks.length === 0) {
                    console.error('[RECORD] No audio chunks recorded!');
                    addMessage('System', 'No audio was recorded. Please try again.', true);
                    elements.recordButton.disabled = false;
                    return;
                }

                // Create blob from recorded chunks using the actual mimeType
                const audioBlob = new Blob(audioChunks, { type: actualMimeType });
                console.log('[RECORD] Audio blob created:', {
                    size: audioBlob.size,
                    type: audioBlob.type
                });
                
                // Stop audio stream
                if (audioStream) {
                    audioStream.getTracks().forEach(track => {
                        track.stop();
                        console.log('[RECORD] Audio track stopped');
                    });
                    audioStream = null;
                }

                // Send audio to backend
                await sendAudio(audioBlob);
            };

            // Start recording with timeslice to get chunks periodically
            mediaRecorder.start(100); // Get chunks every 100ms
            isRecording = true;
            console.log('[RECORD] Recording started');
            
            // Update UI
            elements.recordButton.innerHTML = '<i class="fas fa-stop me-2"></i>Stop';
            elements.recordButton.classList.remove('btn-info');
            elements.recordButton.classList.add('btn-danger');
            elements.recordingStatus.hidden = false;
            updateStatus('Recording...', 'warning');

        } catch (error) {
            console.error('[RECORD] Error starting recording:', error);
            
            // Provide user-friendly error messages
            let errorMessage = error.message;
            if (error.name === 'NotAllowedError') {
                errorMessage = 'Microphone access denied. Please allow microphone access and try again.';
            } else if (error.name === 'NotFoundError') {
                errorMessage = 'No microphone found. Please connect a microphone and try again.';
            } else if (error.name === 'NotSupportedError') {
                errorMessage = 'Audio recording is not supported in this browser.';
            }
            
            addMessage('System', `Error accessing microphone: ${errorMessage}`, true);
            isRecording = false;
            elements.recordButton.disabled = false;
            
            // Clean up if stream was created
            if (audioStream) {
                audioStream.getTracks().forEach(track => track.stop());
                audioStream = null;
            }
        }
    }

    function stopRecording() {
        if (mediaRecorder && isRecording) {
            mediaRecorder.stop();
            isRecording = false;
            
            // Update UI
            elements.recordButton.innerHTML = '<i class="fas fa-microphone me-2"></i>Voice';
            elements.recordButton.classList.remove('btn-danger');
            elements.recordButton.classList.add('btn-info');
            elements.recordingStatus.hidden = true;
            elements.recordButton.disabled = true;
            updateStatus('Processing audio...', 'warning');
        }
    }

    async function sendAudio(audioBlob) {
        if (!isSessionActive || !sessionData) {
            addMessage('System', 'Session not active. Please start a session first.', true);
            elements.recordButton.disabled = false;
            return;
        }

        if (!audioBlob || audioBlob.size === 0) {
            console.error('[AUDIO] Audio blob is empty or invalid');
            addMessage('System', 'No audio data to send. Please try recording again.', true);
            elements.recordButton.disabled = false;
            return;
        }

        try {
            showLoading('Processing audio...');
            updateStatus('Sending audio...', 'warning');
            
            // Determine file extension based on blob type
            let fileExtension = 'webm';
            if (audioBlob.type.includes('ogg')) {
                fileExtension = 'ogg';
            } else if (audioBlob.type.includes('mp4') || audioBlob.type.includes('mpeg')) {
                fileExtension = 'mp4';
            } else if (audioBlob.type.includes('wav')) {
                fileExtension = 'wav';
            }
            
            const fileName = `recording.${fileExtension}`;
            console.log('[AUDIO] Preparing to send audio:', {
                size: audioBlob.size,
                type: audioBlob.type,
                fileName: fileName
            });
            
            // Create FormData - ensure field names match backend expectations
            const formData = new FormData();
            formData.append('audio', audioBlob, fileName);
            formData.append('conversationId', sessionData.sessionId);
            
            if (streamingToken) {
                formData.append('streamingToken', streamingToken);
                console.log('[AUDIO] Including streamingToken (length:', streamingToken.length, ')');
            } else {
                console.warn('[AUDIO] WARNING: streamingToken is missing!');
            }

            // Log FormData contents for debugging
            console.log('[AUDIO] FormData contents:');
            for (const [key, value] of formData.entries()) {
                if (value instanceof File || value instanceof Blob) {
                    console.log(`  ${key}: [Blob/File] size=${value.size}, type=${value.type}`);
                } else {
                    console.log(`  ${key}: ${value}`);
                }
            }

            // Send to backend
            console.log('[API] Calling POST', `${API_BASE}/audio`, {
                conversationId: sessionData.sessionId,
                hasStreamingToken: !!streamingToken,
                audioSize: audioBlob.size,
                audioType: audioBlob.type
            });
            
            const response = await fetch(`${API_BASE}/audio`, {
                method: 'POST',
                body: formData
                // Note: Don't set Content-Type header - browser will set it with boundary for multipart/form-data
            });

            console.log('[API] /audio response status:', response.status, response.statusText);

            if (!response.ok) {
                let errorMessage = `HTTP ${response.status}`;
                let errorDetails = null;
                
                try {
                    const errorData = await response.json();
                    errorMessage = errorData.error || errorData.message || errorMessage;
                    errorDetails = errorData;
                    console.error('[API] /audio error response:', errorDetails);
                } catch (e) {
                    try {
                        const errorText = await response.text();
                        errorMessage = errorText || errorMessage;
                        console.error('[API] /audio error text:', errorText);
                    } catch (e2) {
                        console.error('[API] /audio - could not parse error response');
                    }
                }
                
                throw new Error(errorMessage);
            }

            const data = await response.json();
            console.log('[API] /audio success:', {
                hasUserTranscript: !!data.userTranscript,
                hasAvatarTranscript: !!data.avatarTranscript,
                sourceCount: data.sources?.length || 0
            });

            // Display user transcript
            if (data.userTranscript) {
                addMessage('User', data.userTranscript);
            }

            // Display avatar response
            if (data.avatarTranscript) {
                addMessage('Avatar', data.avatarTranscript);
            }

            // Update sources
            if (data.sources) {
                updateSources(data.sources, data.isFallback);
            }

            hideLoading();
            updateStatus('Connected', 'success');

        } catch (error) {
            console.error('[AUDIO] Error sending audio:', error);
            console.error('[AUDIO] Error details:', {
                name: error.name,
                message: error.message,
                stack: error.stack
            });
            
            addMessage('System', `Error: ${error.message}`, true);
            hideLoading();
            updateStatus('Error', 'danger');
        } finally {
            elements.recordButton.disabled = false;
        }
    }

    function toggleRecording() {
        // Prefer browser speech recognition if available
        if (recognition) {
            console.log('[STT] Using Web Speech API for speech-to-text');
            try {
                elements.recordButton.disabled = true;
                elements.recordButton.innerHTML = '<i class="fas fa-microphone me-2"></i>Listening...';
                elements.recordButton.classList.remove('btn-info');
                elements.recordButton.classList.add('btn-danger');
                elements.recordingStatus.hidden = false;
                updateStatus('Listening...', 'warning');
                recognition.start();
            } catch (err) {
                console.error('[STT] Error starting recognition, falling back to MediaRecorder:', err);
                // Fall through to existing MediaRecorder path
            }

            // If recognition started successfully, stop here
            return;
        }

        // Fallback: existing MediaRecorder + Whisper pipeline
        if (!isRecording) {
            startRecording();
        } else {
            stopRecording();
        }
    }

    // ============================================
    // Event Listeners
    // ============================================
    elements.startButton.addEventListener('click', startSession);
    elements.stopButton.addEventListener('click', stopSessionHandler);
    elements.sendButton.addEventListener('click', sendMessage);
    elements.recordButton.addEventListener('click', toggleRecording);
    elements.messageInput.addEventListener('keypress', (e) => {
        if (e.key === 'Enter' && !e.shiftKey && isSessionActive) {
            e.preventDefault();
            sendMessage();
        }
    });

    // Cleanup on page unload
    window.addEventListener('beforeunload', async () => {
        if (sessionData) {
            await stopSession(sessionData.sessionId);
        }
        if (liveKitRoom) {
            try {
                liveKitRoom.disconnect();
            } catch (e) {
                console.error('Error disconnecting on unload:', e);
            }
        }
    });

    console.log('Avatar page initialized');
    console.log('[INIT] API_BASE:', API_BASE);
    console.log('[INIT] Start button element:', elements.startButton);
    console.log('[INIT] Video element:', elements.video);
    console.log('[INIT] Event listeners attached');
    console.log('[INIT] Use checkVideoState() in console to debug video element');
    console.log('[INIT] Use forceVideoVisible() in console to force video visibility for testing');
    
    // Verify API endpoint is reachable
    console.log('[INIT] Testing API endpoint availability...');
    fetch(`${API_BASE}/session/create`, { method: 'OPTIONS' })
        .then(() => console.log('[INIT] API endpoint is reachable'))
        .catch(err => console.warn('[INIT] API endpoint test failed (this is OK):', err));
    
    // Periodically check video state (for debugging)
    setInterval(() => {
        if (isSessionActive && elements.video && !elements.video.hidden) {
            const v = elements.video;
            if (v.readyState >= 2 && v.paused) {
                console.warn('[LK] Video is ready but paused - attempting to play...');
                v.play().catch(err => console.error('[LK] Auto-play failed:', err));
            }
        }
    }, 5000); // Check every 5 seconds
})();
</script>
}
