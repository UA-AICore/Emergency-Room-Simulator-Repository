@page
@model AvatarModel
@{
    ViewData["Title"] = "Medical Instructor Avatar";
}

<link rel="stylesheet" href="~/css/custom.css" />
<style>
    @@keyframes pulse {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.5; }
    }
    .fa-circle[style*="animation"] {
        display: inline-block;
    }
</style>

<div class="container-fluid h-100 py-4">
    <div class="row h-100 g-4">
        <!-- Main Avatar Area -->
        <div class="col-lg-12 d-flex flex-column">
            <div class="chat-container flex-grow-1 d-flex flex-column">
                <!-- Header -->
                <div class="chat-header">
                    <h4 class="mb-2">
                        <i class="fas fa-user-md me-2"></i>
                        Medical Instructor Avatar
                        <span class="badge bg-light text-dark ms-2" id="statusBadge">
                            <i class="fas fa-circle text-secondary"></i> Ready
                        </span>
                    </h4>
                    <small class="text-white-50">
                        <i class="fas fa-id-card me-1"></i>
                        Session: <span id="sessionIdDisplay">-</span>
                    </small>
                </div>
                
                <!-- Video Container -->
                <div class="avatar-video-container position-relative" style="background: #000; min-height: 500px; display: flex; align-items: center; justify-content: center;">
                    <video id="avatarVideo" autoplay playsinline muted style="width: 100%; max-width: 800px; border: 1px solid #ccc; background:#000;" hidden></video>
                    <audio id="avatarAudio" autoplay volume="1.0"></audio>
                    <div id="placeholder" class="text-center text-white p-5">
                        <i class="fas fa-user-md fa-5x mb-4" style="opacity: 0.5;"></i>
                        <h5>Medical Instructor Avatar</h5>
                        <p class="text-white-50">Click "Start Session" to begin your conversation</p>
                    </div>
                    <div id="loading" class="text-center text-white p-5" hidden>
                        <div class="spinner-border text-light mb-3" role="status"></div>
                        <p id="loadingText">Connecting...</p>
                    </div>
                </div>
                
                <!-- Chat History -->
                <div class="chat-messages" id="chatHistory" style="height: 200px; overflow-y: auto; background: #f8f9fa; padding: 1rem;">
                    <div class="text-center text-muted py-4">
                        <i class="fas fa-comments fa-2x mb-2"></i>
                        <p class="mb-0">Conversation transcript will appear here</p>
                    </div>
                </div>
                
                <!-- Input Controls -->
                <div class="chat-input-container">
                    <div class="input-group">
                        <input type="text" id="messageInput" class="form-control" placeholder="Ask your medical question..." maxlength="500" disabled>
                        <button class="btn btn-primary" type="button" id="sendButton" disabled>
                            <i class="fas fa-paper-plane me-2"></i>Send
                        </button>
                        <button class="btn btn-info" type="button" id="recordButton" disabled>
                            <i class="fas fa-microphone me-2"></i>Voice
                        </button>
                        <button class="btn btn-success" type="button" id="startButton">
                            <i class="fas fa-play me-2"></i>Start Session
                        </button>
                        <button class="btn btn-danger" type="button" id="stopButton" hidden>
                            <i class="fas fa-stop me-2"></i>Stop Session
                        </button>
                    </div>
                    <div class="mt-2 d-flex justify-content-between align-items-center">
                        <small class="text-muted">
                            <i class="fas fa-keyboard me-1"></i>
                            Type or <i class="fas fa-microphone me-1"></i> speak your question
                        </small>
                        <small class="text-muted">
                            <i class="fas fa-video me-1"></i>
                            Powered by HeyGen Avatar + RAG-enhanced medical knowledge
                        </small>
                    </div>
                    <div id="recordingStatus" class="mt-2" hidden>
                        <small class="text-warning">
                            <i class="fas fa-circle me-1" style="animation: pulse 1s infinite;"></i>
                            Recording... Click again to stop and send
                        </small>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

@section Scripts {
<!-- LiveKit Client Library -->
<script src="https://cdn.jsdelivr.net/npm/livekit-client/dist/livekit-client.umd.min.js"></script>
<script>
(function() {
    'use strict';

    // ============================================
    // Configuration & State
    // ============================================
    const API_BASE = '/api/avatar/v2/streaming';
    let liveKitRoom = null;
    let sessionData = null;
    let streamingToken = null; // Cache the token used to create the session
    let isSessionActive = false;
    
    // Helper function to check video element state (can be called from console)
    window.checkVideoState = function() {
        const v = document.getElementById('avatarVideo');
        if (!v) {
            console.log('[DEBUG] Video element not found');
            return null;
        }
        
        const computedStyle = window.getComputedStyle(v);
        const state = {
            element: v,
            currentTime: v.currentTime,
            paused: v.paused,
            readyState: v.readyState,
            videoWidth: v.videoWidth,
            videoHeight: v.videoHeight,
            muted: v.muted,
            hidden: v.hidden,
            srcObject: !!v.srcObject,
            srcObjectTracks: v.srcObject ? {
                video: v.srcObject.getVideoTracks().length,
                audio: v.srcObject.getAudioTracks().length
            } : null,
            computedStyle: {
                display: computedStyle.display,
                visibility: computedStyle.visibility,
                width: computedStyle.width,
                height: computedStyle.height,
                zIndex: computedStyle.zIndex,
                position: computedStyle.position,
                opacity: computedStyle.opacity
            }
        };
        
        console.log('[DEBUG] Video element state:', state);
        return state;
    };
    
    // Helper function to force video visibility (for debugging)
    window.forceVideoVisible = function() {
        const v = document.getElementById('avatarVideo');
        if (!v) {
            console.error('[DEBUG] Video element not found');
            return;
        }
        
        // Force visibility with inline styles
        v.style.position = 'relative';
        v.style.width = '640px';
        v.style.height = '360px';
        v.style.zIndex = '9999';
        v.style.background = 'black';
        v.style.display = 'block';
        v.style.visibility = 'visible';
        v.hidden = false;
        
        // Hide placeholder
        const placeholder = document.getElementById('placeholder');
        if (placeholder) {
            placeholder.hidden = true;
        }
        
        // Try to play
        v.play().catch(err => console.error('[DEBUG] Force play failed:', err));
        
        console.log('[DEBUG] Video forced visible - check if avatar is moving now');
        console.log('[DEBUG] Video state:', window.checkVideoState());
    };
    
    // Audio recording state
    let mediaRecorder = null;
    let audioChunks = [];
    let isRecording = false;
    let audioStream = null;

    // ============================================
    // DOM Elements
    // ============================================
    const elements = {
        video: document.getElementById('avatarVideo'),
        audio: document.getElementById('avatarAudio'),
        placeholder: document.getElementById('placeholder'),
        loading: document.getElementById('loading'),
        loadingText: document.getElementById('loadingText'),
        chatHistory: document.getElementById('chatHistory'),
        messageInput: document.getElementById('messageInput'),
        sendButton: document.getElementById('sendButton'),
        recordButton: document.getElementById('recordButton'),
        startButton: document.getElementById('startButton'),
        stopButton: document.getElementById('stopButton'),
        statusBadge: document.getElementById('statusBadge'),
        sessionIdDisplay: document.getElementById('sessionIdDisplay'),
        recordingStatus: document.getElementById('recordingStatus')
    };

    // ============================================
    // Utility Functions
    // ============================================
    function escapeHtml(text) {
        const div = document.createElement('div');
        div.textContent = text;
        return div.innerHTML;
    }

    function updateStatus(text, type = 'secondary') {
        const icons = {
            secondary: 'fa-circle',
            success: 'fa-circle',
            warning: 'fa-circle',
            danger: 'fa-circle'
        };
        elements.statusBadge.innerHTML = `<i class="fas ${icons[type]} text-${type}"></i> ${text}`;
    }

    function showLoading(text = 'Loading...') {
        elements.loadingText.textContent = text;
        elements.loading.hidden = false;
        elements.placeholder.hidden = true;
    }

    function hideLoading() {
        elements.loading.hidden = true;
    }

    function addMessage(sender, message, isError = false) {
        // Remove placeholder
        const placeholder = elements.chatHistory.querySelector('.text-center');
        if (placeholder) placeholder.remove();

        const messageDiv = document.createElement('div');
        messageDiv.className = `mb-2 p-2 rounded ${isError ? 'bg-danger text-white' : sender === 'User' ? 'bg-primary text-white ms-auto' : 'bg-light'}`;
        messageDiv.style.maxWidth = '85%';
        messageDiv.style.marginLeft = sender === 'User' ? 'auto' : '0';

        const icon = sender === 'User' ? 'fa-user' : isError ? 'fa-exclamation-circle' : 'fa-user-md';
        const escapedMessage = escapeHtml(message).replace(/\n/g, '<br>');
        
        messageDiv.innerHTML = `
            <div class="d-flex align-items-start">
                <span><i class="fas ${icon} me-2"></i></span>
                <div class="flex-grow-1">
                    <strong>${escapeHtml(sender)}:</strong>
                    <div>${escapedMessage}</div>
                    <small class="text-muted">${new Date().toLocaleTimeString()}</small>
                </div>
            </div>
        `;

        elements.chatHistory.appendChild(messageDiv);
        elements.chatHistory.scrollTop = elements.chatHistory.scrollHeight;
    }


    // ============================================
    // LiveKit Connection
    // ============================================
    async function connectToLiveKit(url, accessToken) {
        return new Promise((resolve, reject) => {
            // Wait for LiveKit client to load
            let attempts = 0;
            const maxAttempts = 20;
            
            function checkLiveKit() {
                const LiveKit = window.LivekitClient;
                if (LiveKit) {
                    try {
                        const room = new LiveKit.Room({
                            adaptiveStream: true,
                            dynacast: true
                        });

                        // Set up event handlers
                        let videoTrackReceived = false;
                        let audioTrackReceived = false;

                        room.on(LiveKit.RoomEvent.TrackSubscribed, (track, publication, participant) => {
                            console.log('[LK] TrackSubscribed:', track.kind, {
                                participant: participant?.identity || 'unknown',
                                sid: track.sid,
                                trackId: track.trackId,
                                isMuted: track.isMuted,
                                isSubscribed: track.isSubscribed
                            });
                            
                            if (track.kind === LiveKit.Track.Kind.Video || track.kind === 'video') {
                                // Use track.attach() like MarvelCrud - this is the LiveKit recommended way
                                track.attach(elements.video);
                                elements.video.muted = true;
                                elements.video.playsInline = true;
                                elements.video.autoplay = true;
                                elements.video.hidden = false;
                                elements.placeholder.hidden = true;
                                videoTrackReceived = true;
                                
                                const playPromise = elements.video.play();
                                if (playPromise !== undefined) {
                                    playPromise
                                        .then(() => {
                                            console.log('[LK] Video play() succeeded');
                                        })
                                        .catch((err) => {
                                            console.error('[LK] Video play error:', err);
                                        });
                                }
                                
                                if (audioTrackReceived) {
                                    hideLoading();
                                    updateStatus('Connected', 'success');
                                } else {
                                    updateStatus('Connecting audio...', 'warning');
                                }
                                
                            } else if (track.kind === LiveKit.Track.Kind.Audio || track.kind === 'audio') {
                                // Use track.attach() like MarvelCrud - this is the LiveKit recommended way
                                console.log('[LK] Audio track subscribed, attaching to element');
                                track.attach(elements.audio);
                                elements.audio.autoplay = true;
                                elements.audio.muted = false;
                                elements.audio.volume = 1.0;
                                audioTrackReceived = true;
                                
                                // Try to play audio - browsers may require user interaction
                                const playPromise = elements.audio.play();
                                if (playPromise !== undefined) {
                                    playPromise
                                        .then(() => {
                                            console.log('[LK] Audio playback started successfully');
                                            if (videoTrackReceived) {
                                                hideLoading();
                                                updateStatus('Connected', 'success');
                                            }
                                        })
                                        .catch((error) => {
                                            console.warn('[LK] Audio play was prevented:', error);
                                        });
                                }
                                
                                if (videoTrackReceived) {
                                    hideLoading();
                                    updateStatus('Connected', 'success');
                                }
                            }
                        });

                        room.on(LiveKit.RoomEvent.TrackUnsubscribed, (track, publication, participant) => {
                            console.log(`Track unsubscribed: ${track.kind} from ${participant?.identity || 'unknown'}`);
                            // Detach track from elements
                            if (track.kind === 'video') {
                                track.detach(elements.video);
                            } else if (track.kind === 'audio') {
                                track.detach(elements.audio);
                            }
                            if (track.kind === 'video') {
                                videoTrackReceived = false;
                                elements.video.hidden = true;
                                elements.placeholder.hidden = false;
                                updateStatus('Video disconnected', 'warning');
                            } else if (track.kind === 'audio') {
                                audioTrackReceived = false;
                                if (videoTrackReceived) {
                                    updateStatus('Audio disconnected', 'warning');
                                }
                            }
                        });

                        room.on(LiveKit.RoomEvent.Disconnected, () => {
                            console.log('Room disconnected');
                            updateStatus('Disconnected', 'danger');
                            isSessionActive = false;
                            elements.messageInput.disabled = true;
                            elements.sendButton.disabled = true;
                        });

                        // Connect with timeout
                        const connectPromise = room.connect(url, accessToken);
                        const timeoutPromise = new Promise((_, rejectTimeout) => 
                            setTimeout(() => rejectTimeout(new Error('Connection timeout after 30 seconds')), 30000)
                        );

                        Promise.race([connectPromise, timeoutPromise])
                            .then(() => {
                                console.log('LiveKit connected successfully');
                                resolve(room);
                            })
                            .catch(reject);
                    } catch (error) {
                        reject(error);
                    }
                } else if (attempts < maxAttempts) {
                    attempts++;
                    setTimeout(checkLiveKit, 500);
                } else {
                    reject(new Error('LiveKit client library failed to load'));
                }
            }

            checkLiveKit();
        });
    }

    // ============================================
    // API Calls
    // ============================================
    async function createSession() {
        console.log('[API] Calling POST', `${API_BASE}/session/create`);
        const response = await fetch(`${API_BASE}/session/create`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' }
        });

        console.log('[API] session/create response status:', response.status, response.statusText);

        if (!response.ok) {
            const error = await response.json();
            console.error('[API] session/create error:', error);
            throw new Error(error.message || `HTTP ${response.status}`);
        }

        const data = await response.json();
        console.log('[API] session/create success:', { 
            sessionId: data.sessionId?.substring(0, 8) + '...', 
            hasStreamingToken: !!data.streamingToken,
            hasUrl: !!data.url,
            hasAccessToken: !!data.accessToken
        });
        return data;
    }

    async function sendTask(sessionId, message) {
        if (!streamingToken) {
            console.error('[API] CRITICAL: streamingToken is missing! Cannot send task.');
            throw new Error('Streaming token is required. Please restart the session.');
        }

        const payload = {
            message: message,
            conversationId: sessionId,
            streamingToken: streamingToken // Include the cached token
        };

        console.log('[API] Calling POST', `${API_BASE}/task`, {
            conversationId: sessionId,
            messageLength: message.length,
            hasStreamingToken: !!streamingToken,
            streamingTokenLength: streamingToken.length
        });

        const response = await fetch(`${API_BASE}/task`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify(payload)
        });

        console.log('[API] /task response status:', response.status, response.statusText);

        if (!response.ok) {
            let errorMessage = `HTTP ${response.status}`;
            try {
                const errorData = await response.json();
                console.error('[API] /task error response:', errorData);
                errorMessage = errorData.error || errorData.message || errorMessage;
            } catch (e) {
                // If response isn't JSON, try to get text
                try {
                    const errorText = await response.text();
                    console.error('[API] /task error text:', errorText);
                    errorMessage = errorText || errorMessage;
                } catch (e2) {
                    // Use default error message
                }
            }
            throw new Error(errorMessage);
        }

        const data = await response.json();
        console.log('[API] /task success:', { 
            hasTranscript: !!data.transcript,
            transcriptLength: data.transcript?.length || 0,
        });
        return data;
    }

    async function stopSession(sessionId) {
        try {
            await fetch(`${API_BASE}/session/stop`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ 
                    sessionId: sessionId,
                    streamingToken: streamingToken // Include the cached token
                })
            });
        } catch (error) {
            console.error('Error stopping session:', error);
        }
    }

    // ============================================
    // Session Management
    // ============================================
    async function startSession() {
        console.log('[SESSION] startSession() called');
        try {
            elements.startButton.disabled = true;
            showLoading('Creating session...');
            updateStatus('Creating session...', 'warning');

            // Step 1: Create streaming session
            console.log('[SESSION] Step 1: Creating session via API...');
            const sessionResponse = await createSession();
            console.log('[SESSION] Session created successfully:', {
                sessionId: sessionResponse.sessionId?.substring(0, 8) + '...',
                hasStreamingToken: !!sessionResponse.streamingToken
            });
            sessionData = sessionResponse;
            streamingToken = sessionResponse.streamingToken; // Cache the token for reuse
            elements.sessionIdDisplay.textContent = sessionResponse.sessionId.substring(0, 8) + '...';

            showLoading('Connecting to avatar...');
            updateStatus('Connecting...', 'warning');

            // Step 2: Connect to LiveKit
            liveKitRoom = await connectToLiveKit(sessionResponse.url, sessionResponse.accessToken);

            // Step 3: Send initial greeting to make avatar animate
            // Note: Avatar will remain static/idle until it receives a task
            try {
                console.log('Sending initial greeting to animate avatar...');
                // Send a greeting that establishes Dr. Dexter as the instructor
                // This will be processed through RAG+personality to create Dr. Dexter's introduction
                const greeting = "Introduce yourself as Dr. Dexter, a medical instructor with decades of ER experience. Tell the student you have access to a comprehensive medical knowledge database and you're ready to teach them about emergency medicine and trauma care. Ask what medical topic they'd like to learn about.";
                const greetingResponse = await sendTask(sessionResponse.sessionId, greeting);
                
                console.log('Greeting sent successfully, avatar should now be animating');
                
                if (greetingResponse.transcript) {
                    addMessage('Avatar', greetingResponse.transcript);
                }
            } catch (error) {
                console.error('Error sending greeting:', error);
                // Inform user but don't fail session
                addMessage('System', `Note: Initial greeting failed (${error.message}). The avatar may appear static until you send a message.`, false);
            }

            // Step 4: Enable UI
            isSessionActive = true;
            elements.messageInput.disabled = false;
            elements.sendButton.disabled = false;
            elements.recordButton.disabled = false;
            elements.startButton.hidden = true;
            elements.stopButton.hidden = false;
            updateStatus('Connected', 'success');

        } catch (error) {
            console.error('Error starting session:', error);
            addMessage('System', `Failed to start session: ${error.message}`, true);
            updateStatus('Error', 'danger');
            hideLoading();
            elements.placeholder.hidden = false;
            elements.startButton.disabled = false;

            // Cleanup
            if (sessionData) {
                await stopSession(sessionData.sessionId);
            }
            if (liveKitRoom) {
                try {
                    liveKitRoom.disconnect();
                } catch (e) {
                    console.error('Error disconnecting:', e);
                }
            }
            
            // Reset state
            sessionData = null;
            streamingToken = null;
        }
    }

    async function stopSessionHandler() {
        try {
            elements.stopButton.disabled = true;
            updateStatus('Stopping...', 'warning');

            if (sessionData) {
                await stopSession(sessionData.sessionId);
            }

            if (liveKitRoom) {
                liveKitRoom.disconnect();
            }

            // Reset UI
            isSessionActive = false;
            sessionData = null;
            liveKitRoom = null;

            elements.video.hidden = true;
            elements.placeholder.hidden = false;
            hideLoading();
            elements.messageInput.disabled = true;
            elements.sendButton.disabled = true;
            elements.recordButton.disabled = true;
            elements.startButton.hidden = false;
            elements.stopButton.hidden = true;
            elements.startButton.disabled = false;
            elements.sessionIdDisplay.textContent = '-';
            updateStatus('Ready', 'secondary');
            sessionData = null;
            streamingToken = null; // Clear cached token
            addMessage('System', 'Session stopped.', false);
            
            // Stop any active recording
            if (isRecording) {
                stopRecording();
            }
            if (audioStream) {
                audioStream.getTracks().forEach(track => track.stop());
                audioStream = null;
            }

        } catch (error) {
            console.error('Error stopping session:', error);
            addMessage('System', `Error stopping session: ${error.message}`, true);
            elements.stopButton.disabled = false;
        }
    }

    async function sendMessage() {
        console.log('[MESSAGE] sendMessage() called');
        const message = elements.messageInput.value.trim();
        if (!message || !isSessionActive) {
            console.warn('[MESSAGE] Cannot send - message empty or session not active', { message: !!message, isSessionActive });
            return;
        }

        if (!sessionData || !sessionData.sessionId) {
            console.error('[MESSAGE] CRITICAL: sessionData is missing!');
            addMessage('System', 'Session not initialized. Please start a session first.', true);
            return;
        }

        if (!streamingToken) {
            console.error('[MESSAGE] CRITICAL: streamingToken is missing!');
            addMessage('System', 'Streaming token missing. Please restart the session.', true);
            return;
        }

        console.log('[MESSAGE] Sending message via API:', {
            sessionId: sessionData.sessionId,
            messageLength: message.length,
            hasStreamingToken: !!streamingToken
        });

        addMessage('User', message);
        elements.messageInput.value = '';
        elements.sendButton.disabled = true;
        showLoading('Processing...');
        updateStatus('Processing...', 'warning');

        try {
            const response = await sendTask(sessionData.sessionId, message);
            
            if (response.transcript) {
                addMessage('Avatar', response.transcript);
            }

            hideLoading();
            updateStatus('Connected', 'success');
        } catch (error) {
            console.error('Error sending message:', error);
            addMessage('System', `Error: ${error.message}`, true);
            hideLoading();
            updateStatus('Error', 'danger');
        } finally {
            elements.sendButton.disabled = false;
        }
    }

    // ============================================
    // Audio Recording Functions
    // ============================================
    
    /**
     * Check if getUserMedia is available and if the page is served securely
     */
    function checkMicrophoneAvailability() {
        // Check if getUserMedia is available
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
            return {
                available: false,
                error: 'getUserMedia API is not available in this browser. Please use a modern browser like Chrome, Firefox, or Edge.'
            };
        }

        // Check if page is served over HTTPS or localhost
        const isSecure = window.location.protocol === 'https:' || 
                        window.location.hostname === 'localhost' || 
                        window.location.hostname === '127.0.0.1' ||
                        window.location.hostname === '[::1]';
        
        if (!isSecure) {
            return {
                available: false,
                error: 'Microphone access requires HTTPS. Please access this page via HTTPS or use localhost.'
            };
        }

        return { available: true };
    }

    async function startRecording() {
        try {
            // First check if microphone access is available
            const availabilityCheck = checkMicrophoneAvailability();
            if (!availabilityCheck.available) {
                addMessage('System', availabilityCheck.error, true);
                isRecording = false;
                elements.recordButton.disabled = false;
                return;
            }

            // Request microphone access
            audioStream = await navigator.mediaDevices.getUserMedia({ 
                audio: {
                    channelCount: 1,
                    sampleRate: 16000,
                    echoCancellation: true,
                    noiseSuppression: true
                } 
            });

            // Create MediaRecorder - prefer formats that Whisper API handles best
            // Try wav first (most compatible), then mp3, then webm, then browser default
            let mimeType = '';
            const preferredTypes = [
                'audio/wav',
                'audio/mp3',
                'audio/mpeg',
                'audio/webm;codecs=opus',
                'audio/webm',
                'audio/mp4',
                'audio/m4a'
            ];
            
            for (const type of preferredTypes) {
                if (MediaRecorder.isTypeSupported(type)) {
                    mimeType = type;
                    console.log('[AUDIO] Using MIME type:', mimeType);
                    break;
                }
            }
            
            if (!mimeType) {
                console.warn('[AUDIO] No preferred MIME type supported, using browser default');
            }

            const recorderOptions = mimeType ? { mimeType: mimeType } : {};
            mediaRecorder = new MediaRecorder(audioStream, recorderOptions);

            audioChunks = [];

            mediaRecorder.ondataavailable = (event) => {
                if (event.data.size > 0) {
                    audioChunks.push(event.data);
                }
            };

            mediaRecorder.onstop = async () => {
                // Create blob from recorded chunks
                const audioBlob = new Blob(audioChunks, { type: mediaRecorder.mimeType || 'audio/webm' });
                
                // Stop audio stream
                if (audioStream) {
                    audioStream.getTracks().forEach(track => track.stop());
                    audioStream = null;
                }

                // Send audio to backend
                await sendAudio(audioBlob);
            };

            mediaRecorder.start();
            isRecording = true;
            
            // Update UI
            elements.recordButton.innerHTML = '<i class="fas fa-stop me-2"></i>Stop';
            elements.recordButton.classList.remove('btn-info');
            elements.recordButton.classList.add('btn-danger');
            elements.recordingStatus.hidden = false;
            updateStatus('Recording...', 'warning');

        } catch (error) {
            console.error('Error starting recording:', error);
            isRecording = false;
            elements.recordButton.disabled = false;
            
            // Provide specific error messages based on error type
            let errorMessage = 'Error accessing microphone: ';
            
            if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
                errorMessage += 'Microphone permission denied. Please allow microphone access in your browser settings and try again.';
            } else if (error.name === 'NotFoundError' || error.name === 'DevicesNotFoundError') {
                errorMessage += 'No microphone found. Please connect a microphone and try again.';
            } else if (error.name === 'NotReadableError' || error.name === 'TrackStartError') {
                errorMessage += 'Microphone is already in use by another application. Please close other applications using the microphone and try again.';
            } else if (error.name === 'OverconstrainedError' || error.name === 'ConstraintNotSatisfiedError') {
                errorMessage += 'Microphone does not support the required settings. Trying with default settings...';
                // Try again with default settings
                try {
                    audioStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    // Retry recording with default settings
                    startRecording();
                    return;
                } catch (retryError) {
                    errorMessage += ' Failed to access microphone even with default settings.';
                }
            } else {
                errorMessage += error.message || 'Unknown error occurred.';
            }
            
            addMessage('System', errorMessage, true);
            updateStatus('Microphone Error', 'danger');
        }
    }

    function stopRecording() {
        if (mediaRecorder && isRecording) {
            mediaRecorder.stop();
            isRecording = false;
            
            // Update UI
            elements.recordButton.innerHTML = '<i class="fas fa-microphone me-2"></i>Voice';
            elements.recordButton.classList.remove('btn-danger');
            elements.recordButton.classList.add('btn-info');
            elements.recordingStatus.hidden = true;
            elements.recordButton.disabled = true;
            updateStatus('Processing audio...', 'warning');
        }
    }

    async function sendAudio(audioBlob) {
        if (!isSessionActive || !sessionData) {
            addMessage('System', 'Session not active. Please start a session first.', true);
            elements.recordButton.disabled = false;
            return;
        }

        // Validate audio blob
        if (!audioBlob || audioBlob.size === 0) {
            addMessage('System', 'No audio recorded. Please try recording again.', true);
            elements.recordButton.disabled = false;
            updateStatus('Recording Error', 'danger');
            return;
        }

        // Check minimum size (very small files are likely empty or corrupted)
        if (audioBlob.size < 1000) { // Less than 1KB is suspicious
            addMessage('System', 'Audio recording is too short or empty. Please record for at least 1-2 seconds.', true);
            elements.recordButton.disabled = false;
            updateStatus('Recording Error', 'danger');
            return;
        }

        try {
            showLoading('Processing audio...');
            
            // Determine file extension based on blob type
            // Match the actual MIME type used for recording
            let fileExtension = 'webm';
            let fileName = 'recording.webm';
            
            if (audioBlob.type) {
                if (audioBlob.type.includes('wav')) {
                    fileExtension = 'wav';
                    fileName = 'recording.wav';
                } else if (audioBlob.type.includes('mp3') || audioBlob.type.includes('mpeg')) {
                    fileExtension = 'mp3';
                    fileName = 'recording.mp3';
                } else if (audioBlob.type.includes('mp4')) {
                    fileExtension = 'mp4';
                    fileName = 'recording.mp4';
                } else if (audioBlob.type.includes('m4a')) {
                    fileExtension = 'm4a';
                    fileName = 'recording.m4a';
                } else if (audioBlob.type.includes('webm')) {
                    fileExtension = 'webm';
                    fileName = 'recording.webm';
                } else {
                    // Default to webm but log warning
                    console.warn('[AUDIO] Unknown blob type:', audioBlob.type, '- using webm as default');
                }
            } else {
                console.warn('[AUDIO] No blob type detected - using webm as default');
            }
            
            console.log('[AUDIO] Sending audio blob:', {
                type: audioBlob.type,
                size: audioBlob.size,
                fileName: fileName,
                extension: fileExtension
            });
            
            // Create FormData
            const formData = new FormData();
            formData.append('audio', audioBlob, fileName);
            formData.append('conversationId', sessionData.sessionId);
            if (streamingToken) {
                formData.append('streamingToken', streamingToken);
            }

            // Send to backend
            console.log('[API] Calling POST', `${API_BASE}/audio`, {
                conversationId: sessionData.sessionId,
                hasStreamingToken: !!streamingToken,
                audioSize: audioBlob.size
            });
            
            const response = await fetch(`${API_BASE}/audio`, {
                method: 'POST',
                body: formData
            });

            console.log('[API] /audio response status:', response.status, response.statusText);

            if (!response.ok) {
                let errorMessage = `HTTP ${response.status}`;
                try {
                    const errorData = await response.json();
                    errorMessage = errorData.error || errorData.message || errorMessage;
                } catch (e) {
                    const errorText = await response.text();
                    errorMessage = errorText || errorMessage;
                }
                throw new Error(errorMessage);
            }

            const data = await response.json();

            // Display user transcript
            if (data.userTranscript) {
                addMessage('User', data.userTranscript);
            }

            // Display avatar response
            if (data.avatarTranscript) {
                addMessage('Avatar', data.avatarTranscript);
            }


            hideLoading();
            updateStatus('Connected', 'success');

        } catch (error) {
            console.error('Error sending audio:', error);
            addMessage('System', `Error: ${error.message}`, true);
            hideLoading();
            updateStatus('Error', 'danger');
        } finally {
            elements.recordButton.disabled = false;
        }
    }

    function toggleRecording() {
        if (!isRecording) {
            startRecording();
        } else {
            stopRecording();
        }
    }

    // ============================================
    // Event Listeners
    // ============================================
    elements.startButton.addEventListener('click', startSession);
    elements.stopButton.addEventListener('click', stopSessionHandler);
    elements.sendButton.addEventListener('click', sendMessage);
    elements.recordButton.addEventListener('click', toggleRecording);
    elements.messageInput.addEventListener('keypress', (e) => {
        if (e.key === 'Enter' && !e.shiftKey && isSessionActive) {
            e.preventDefault();
            sendMessage();
        }
    });

    // Cleanup on page unload
    window.addEventListener('beforeunload', async () => {
        if (sessionData) {
            await stopSession(sessionData.sessionId);
        }
        if (liveKitRoom) {
            try {
                liveKitRoom.disconnect();
            } catch (e) {
                console.error('Error disconnecting on unload:', e);
            }
        }
    });

    console.log('Avatar page initialized');
    console.log('[INIT] API_BASE:', API_BASE);
    console.log('[INIT] Start button element:', elements.startButton);
    console.log('[INIT] Video element:', elements.video);
    console.log('[INIT] Event listeners attached');
    console.log('[INIT] Use checkVideoState() in console to debug video element');
    console.log('[INIT] Use forceVideoVisible() in console to force video visibility for testing');
    
    // Verify API endpoint is reachable
    console.log('[INIT] Testing API endpoint availability...');
    fetch(`${API_BASE}/session/create`, { method: 'OPTIONS' })
        .then(() => console.log('[INIT] API endpoint is reachable'))
        .catch(err => console.warn('[INIT] API endpoint test failed (this is OK):', err));
    
    // Periodically check video state (for debugging)
    setInterval(() => {
        if (isSessionActive && elements.video && !elements.video.hidden) {
            const v = elements.video;
            if (v.readyState >= 2 && v.paused) {
                console.warn('[LK] Video is ready but paused - attempting to play...');
                v.play().catch(err => console.error('[LK] Auto-play failed:', err));
            }
        }
    }, 5000); // Check every 5 seconds
})();
</script>
}

